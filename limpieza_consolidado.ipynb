{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b69ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "carpeta = \"Data encontrada\"\n",
    "\n",
    "# Lista para almacenar cada DataFrame\n",
    "dataframes = []\n",
    "\n",
    "#dff = pd.read_excel('Data encontrada/resultados_inalco.xlsx')\n",
    "\n",
    "for archivo in os.listdir(carpeta):\n",
    "    if archivo.endswith(\".xlsx\") or archivo.endswith(\".xls\"):\n",
    "        ruta = os.path.join(carpeta, archivo)\n",
    "        #print(f\"Leyendo: {archivo}\")\n",
    "        df = pd.read_excel(ruta)\n",
    "        nombre_archivo = os.path.splitext(archivo)[0]  # Quita la extensión\n",
    "        df[\"Pagina\"] = nombre_archivo.replace(\"resultados_\", \"\")\n",
    "        df[\"Pagina\"] = df[\"Pagina\"].str.upper()\n",
    "        dataframes.append(df)\n",
    "\n",
    "df_concatenado = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8280f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_takora = pd.read_excel('Data encontrada/resultados_takora.xlsx')\n",
    "\n",
    "# df_takora['Nombre Normalizado'] = (\n",
    "#     df_takora['Nombre Producto']\n",
    "#       .astype(str)\n",
    "#       # split por •, , , ( o la palabra Medida\n",
    "#       .str.split(r'(?:•|,|\\(|/|Medida)', n=1, regex=True)\n",
    "#       .str[0]\n",
    "#       .str.strip()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b932ff",
   "metadata": {},
   "source": [
    "LIMPIEZA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad481237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina\n",
      "CHILEREPUESTOS     4737\n",
      "MUNDOREPUESTOS     4251\n",
      "TAKORA              636\n",
      "INALCO              296\n",
      "CASADEREPUESTOS     194\n",
      "AUTOPLANET          130\n",
      "EMGI                 40\n",
      "ULTI                 18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def quitar_acentos(texto: str) -> str:\n",
    "    nkfd = unicodedata.normalize('NFD', str(texto))\n",
    "    return ''.join([c for c in nkfd if not unicodedata.combining(c)])\n",
    "\n",
    "df_concatenado = df_concatenado.drop_duplicates(subset=[ 'Link']) #'Nombre Producto',\n",
    "\n",
    "\n",
    "df_concatenado['Precio'] = (\n",
    "    df_concatenado['Precio']\n",
    "    .astype(str)\n",
    "    .str.replace('$', '', regex=False)\n",
    "    .str.replace('.', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "df_concatenado['Precio'] = pd.to_numeric(df_concatenado['Precio'], errors='coerce')\n",
    "\n",
    "df_precios_cero = df_concatenado[df_concatenado['Precio'].isna() | (df_concatenado['Precio'] == 0)].copy()\n",
    "df_concatenado = df_concatenado[~df_concatenado.index.isin(df_precios_cero.index)].copy()\n",
    "\n",
    "#QUITAR DATA DE CIPER\n",
    "df_ciper = df_concatenado[df_concatenado['Pagina'] == 'CIPER'].copy()\n",
    "df_concatenado = df_concatenado[~df_concatenado['Pagina'].isin(['CIPER'])].copy()\n",
    "\n",
    "mask_dup = df_concatenado.duplicated(subset=['Nombre Producto'], keep=False)\n",
    "df_nombres_duplicados = df_concatenado[mask_dup].copy()\n",
    "df_concatenado = df_concatenado[~mask_dup].copy()\n",
    "df_concatenado['Nombre Producto'] = df_concatenado['Nombre Producto'].apply(quitar_acentos)\n",
    "\n",
    "\n",
    "conteos = df_nombres_duplicados['Pagina'].value_counts()\n",
    "print(conteos)\n",
    "\n",
    "\n",
    "\n",
    "# df_nombres_repetidos = df_nombres_duplicados[~df_nombres_duplicados[\"Pagina\"].isin([\"MUNDOREPUESTOS\",\"CHILEREPUESTOS\",\"CIPER\",])]\n",
    "# df_nombres_duplicados = df_nombres_duplicados[df_nombres_duplicados[\"Pagina\"].isin([\"MUNDOREPUESTOS\",\"CHILEREPUESTOS\",\"CIPER\",])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "756c8356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina\n",
      "TAKORA            5391\n",
      "AUTOPLANET        2604\n",
      "INALCO             863\n",
      "EMGI               850\n",
      "CHILEREPUESTOS     705\n",
      "MUNDOREPUESTOS     638\n",
      "SALFAREPUESTOS     386\n",
      "CIPER              297\n",
      "ULTI                18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conteos = df_concatenado['Pagina'].value_counts()\n",
    "print(conteos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c64a1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas= [\n",
    "    'Chevrolet', 'Hyundai', 'Nissan', 'Toyota', 'Kia',\n",
    "    'Susuki', 'Peugeot', 'Ford', 'Mazda', 'Mitsubishi'\n",
    "]\n",
    "\n",
    "modelos= [\n",
    "    'Spark', 'Aveo', 'Sail', 'Cruze', 'Malibu', 'Tracker', 'Captiva', 'S10',\n",
    "    'Accent', 'Elantra', 'Sonata', 'Tucson', 'Santa Fe', 'Creta', 'i10', 'Kona',\n",
    "    'Sentra', 'Altima', 'Versa', 'March', 'X-Trail', 'Pathfinder', 'Frontier', 'Z Series',\n",
    "    'Corolla', 'Camry', 'Yaris', 'Hilux', 'RAV4', 'Land Cruiser', 'Prius', 'Supra',\n",
    "    'Picanto', 'Rio', 'Cerato', 'Sportage', 'Sorento', 'Soul', 'Seltos', 'Carnival',\n",
    "    'Swift', 'Alto', 'Baleno', 'Celerio', 'Vitara', 'Jimny', 'SX4', 'Ertiga',\n",
    "    '208', '308', '508', '2008', '3008', '5008', 'Partner', 'Rifter',\n",
    "    'Fiesta', 'Focus', 'Mustang', 'Ranger', 'F-150', 'Escape', 'Explorer', 'Maverick',\n",
    "    'Mazda2', 'Mazda3', 'Mazda6', 'CX-3', 'CX-5', 'CX-9', 'BT-50', 'MX-5',\n",
    "    'Lancer', 'Mirage', 'Outlander', 'Outlander Sport', 'ASX', 'Eclipse Cross', 'Montero Sport', 'L200'\n",
    "]\n",
    "\n",
    "\n",
    "df_dicc_ciper = pd.read_excel('Data consolidada/marca_modelo_ciper2.xlsx')\n",
    "\n",
    "df_ciper = df_ciper.drop(['Marca Buscada', 'Modelo Buscado'], axis=1)\n",
    "\n",
    "\n",
    "df_ciper = pd.merge(\n",
    "    df_ciper,\n",
    "    df_dicc_ciper,\n",
    "    on='Link',\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "\n",
    "df_ciper.rename(\n",
    "    columns={\n",
    "        'Marca': 'Marca Buscada',\n",
    "        'Modelo': 'Modelo Buscado'\n",
    "    },\n",
    "    inplace=True  # modifica df directamente\n",
    ")\n",
    "\n",
    "df_ulti = df_concatenado[df_concatenado['Pagina'] == 'ULTI'].copy()\n",
    "df_inalco = df_concatenado[df_concatenado['Pagina'] == 'INALCO'].copy()\n",
    "df_valido = df_concatenado[~df_concatenado['Pagina'].isin(['ULTI', 'INALCO'])].copy()\n",
    "\n",
    "df_ulti_ciper = pd.concat([df_ulti, df_ciper], ignore_index=True)\n",
    "\n",
    "def extraer_por_contains(texto, keywords):\n",
    "    texto = str(texto).lower()\n",
    "    for kw in keywords:\n",
    "        if kw.lower() in texto:\n",
    "            return kw\n",
    "    return None\n",
    "\n",
    "# Aplica sobre tu df_ciper\n",
    "df_ulti_ciper['Marca Buscada'] = df_ulti_ciper['Marca Buscada'] \\\n",
    "    .apply(lambda x: extraer_por_contains(x, marcas))\n",
    "\n",
    "df_ulti_ciper['Modelo Buscado'] = df_ulti_ciper['Modelo Buscado'] \\\n",
    "    .apply(lambda x: extraer_por_contains(x, modelos))\n",
    "\n",
    "df_ulti_ciper.dropna(\n",
    "    subset=['Marca Buscada', 'Modelo Buscado'],\n",
    "    how='any',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa384409",
   "metadata": {},
   "source": [
    "GUARDANDO ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(text):\n",
    "    clean = re.sub(r'[^0-9a-z]+', ' ', text.lower())\n",
    "    return re.sub(r'\\s+', ' ', clean).strip()\n",
    "\n",
    "\n",
    "\n",
    "marcas_set  = set(marcas)\n",
    "modelos_set = set(modelos)\n",
    "\n",
    "\n",
    "\n",
    "#BUSCA LA MARCA Y EL MODELO EN EL NOMBRE DEL REPUESTO\n",
    "def contiene_marca_modelo_por_listas(row):\n",
    "    nombre = normalize(row[\"Nombre Producto\"])\n",
    "    encontrada_marca = any(normalize(m) in nombre for m in marcas_set)\n",
    "    encontrado_modelo = any(normalize(m) in nombre for m in modelos_set)\n",
    "    return encontrada_marca and encontrado_modelo\n",
    "\n",
    "\n",
    "\n",
    "df_valido = df_concatenado[df_concatenado.apply(contiene_marca_modelo_por_listas, axis=1)].copy()\n",
    "df_no_valido = df_concatenado[~df_concatenado.apply(contiene_marca_modelo_por_listas, axis=1)].copy()\n",
    "\n",
    "df_valido = pd.concat([df_valido, df_inalco, df_ulti_ciper], ignore_index=True)\n",
    "\n",
    "df_repuestos = pd.read_csv('Tipos repuestos/tipos_repuestos.csv')\n",
    "lista_repuestos = df_repuestos['repuestos'].dropna().tolist()\n",
    "\n",
    "lista_repuestos = [str(r).strip().lower() for r in lista_repuestos]\n",
    "\n",
    "def detectar_tipo_repuesto(nombre_producto):\n",
    "    nombre = str(nombre_producto).lower()\n",
    "    for repuesto in lista_repuestos:\n",
    "        if repuesto in nombre:\n",
    "            return repuesto\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar la función\n",
    "df_valido['tipo_repuesto'] = df_valido['Nombre Producto'].apply(detectar_tipo_repuesto)\n",
    "\n",
    "\n",
    "df_con_tipo = df_valido[df_valido['tipo_repuesto'].notna()].copy()\n",
    "\n",
    "\n",
    "mask_takora = df_con_tipo['Pagina'].str.contains('TAKORA', case=False, na=False)\n",
    "df_con_tipo.loc[mask_takora, 'Nombre Producto'] = (\n",
    "    df_con_tipo.loc[mask_takora, 'Nombre Producto']\n",
    "      .astype(str)\n",
    "      .str.split(r'(?:•|,|\\(|/|Medida)', n=1, regex=True)\n",
    "      .str[0]\n",
    "      .str.strip()\n",
    ")\n",
    "\n",
    "\n",
    "columnas_necesarias = ['Nombre Producto', 'Marca Buscada', 'Modelo Buscado','tipo_repuesto', 'Precio', 'Pagina', 'Link', 'Imagen', 'Descripción', 'fecha_carga']\n",
    "df_con_tipo = df_con_tipo[columnas_necesarias].copy()\n",
    "\n",
    "# Paso 2: Renombrar columnas\n",
    "nuevos_nombres = {\n",
    "    'Nombre Producto': 'nombre',\n",
    "    'Marca Buscada': 'marca',\n",
    "    'Modelo Buscado': 'modelo',\n",
    "    'Precio': 'precio',\n",
    "    'Pagina': 'pagina',\n",
    "    'Link': 'link',\n",
    "    'Imagen': 'imagen',\n",
    "    'Descripción': 'descripcion',\n",
    "    'fecha_carga' : 'fecha_carga'\n",
    "}\n",
    "df_con_tipo.rename(columns=nuevos_nombres, inplace=True)\n",
    "df_con_tipo.to_excel('data_carga.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "499bfdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pagina\n",
      "TAKORA            3324\n",
      "CIPER              974\n",
      "INALCO             800\n",
      "AUTOPLANET         481\n",
      "MUNDOREPUESTOS     449\n",
      "EMGI               402\n",
      "CHILEREPUESTOS     271\n",
      "ULTI                18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conteos = df_con_tipo['pagina'].value_counts()\n",
    "print(conteos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
